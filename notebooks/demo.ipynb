{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACHI Demo: Human-AI Co-design for Clinical Prediction Models\n",
    "\n",
    "This notebook demonstrates the HACHI framework using a fictional clinical scenario: **Quantum Temporal Dissonance Syndrome (QTDS)** - a whimsical condition where patients experience temporal perception anomalies.\n",
    "\n",
    "> **Note**: This demo uses a completely fictional condition to clearly distinguish from real medical claims while demonstrating the method.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. How HACHI generates initial concepts from clinical notes\n",
    "2. How the AI agent iteratively refines concepts based on performance\n",
    "3. How human feedback guides the co-design process\n",
    "4. How to interpret the resulting concept-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and load our demo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\".\").parent.absolute()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# For display\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Demo Dataset\n",
    "\n",
    "Our demo dataset contains 80 synthetic patient notes for the fictional condition QTDS (Quantum Temporal Dissonance Syndrome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the demo dataset\n",
    "data_path = project_root / \"data\" / \"demo_patients.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nOutcome distribution:\")\n",
    "print(df['outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a sample patient note\n",
    "sample_idx = 0\n",
    "print(f\"Patient ID: {df.iloc[sample_idx]['patient_id']}\")\n",
    "print(f\"Outcome: {df.iloc[sample_idx]['outcome']}\")\n",
    "print(f\"\\n--- Clinical Note ---\\n\")\n",
    "print(df.iloc[sample_idx]['note_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Round 1: Initial Exploration\n",
    "\n",
    "In Round 1, we run the HACHI AI agent loop with default prompts to generate an initial set of concepts.\n",
    "\n",
    "## Step 1.1: Configure the Training\n",
    "\n",
    "We configure the ensemble trainer with parameters suitable for our demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Round 1\n",
    "# Note: In practice, you would run this with a real LLM API\n",
    "# For this demo, we'll use pre-computed outputs\n",
    "\n",
    "round1_config = {\n",
    "    \"init_seeds\": [1, 2, 3],  # Multiple seeds for ensemble diversity\n",
    "    \"num_meta_concepts\": 5,   # Number of concepts to learn\n",
    "    \"num_epochs\": 2,          # Greedy refinement epochs\n",
    "    \"llm_model\": \"gpt-4o-mini\",\n",
    "}\n",
    "\n",
    "print(\"Round 1 Configuration:\")\n",
    "for k, v in round1_config.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Run the AI Agent Loop (Pre-computed)\n",
    "\n",
    "The code below shows how you would run the HACHI training loop. For this demo, we use pre-computed outputs so you can run the notebook without API access.\n",
    "\n",
    "```python\n",
    "# This is the actual code to run HACHI (requires LLM API access)\n",
    "from src.ensemble_trainer import EnsembleTrainer, EnsembleConfig\n",
    "\n",
    "config = EnsembleConfig(\n",
    "    init_seeds=round1_config[\"init_seeds\"],\n",
    "    num_meta_concepts=round1_config[\"num_meta_concepts\"],\n",
    "    num_epochs=round1_config[\"num_epochs\"],\n",
    "    llm_model=round1_config[\"llm_model\"],\n",
    "    # ... additional configuration\n",
    ")\n",
    "\n",
    "trainer = EnsembleTrainer(config=config, output_dir=\"output/round1\")\n",
    "histories = await trainer.fit(data_df=df, plot_aucs=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-computed results from Round 1\n",
    "# These represent typical output from the HACHI agent loop\n",
    "\n",
    "round1_concepts = [\n",
    "    \"Does the patient report experiencing time moving at different speeds?\",\n",
    "    \"Does the patient describe temporal perception anomalies (déjà vu, echoes, etc.)?\",\n",
    "    \"Is there history of exposure to quantum computing equipment?\",\n",
    "    \"Does the Temporal Orientation Test show abnormal results?\",\n",
    "    \"Does the patient report feeling 'unstuck in time'?\",\n",
    "]\n",
    "\n",
    "round1_coefficients = {\n",
    "    \"Does the patient report experiencing time moving at different speeds?\": 2.34,\n",
    "    \"Does the patient describe temporal perception anomalies (déjà vu, echoes, etc.)?\": 1.87,\n",
    "    \"Is there history of exposure to quantum computing equipment?\": 1.45,\n",
    "    \"Does the Temporal Orientation Test show abnormal results?\": 1.23,\n",
    "    \"Does the patient report feeling 'unstuck in time'?\": 0.98,\n",
    "}\n",
    "\n",
    "round1_performance = {\n",
    "    \"train_auc\": 0.89,\n",
    "    \"test_auc\": 0.84,\n",
    "    \"train_accuracy\": 0.82,\n",
    "    \"test_accuracy\": 0.78,\n",
    "}\n",
    "\n",
    "print(\"Round 1 Learned Concepts:\")\n",
    "print(\"=\" * 60)\n",
    "for i, concept in enumerate(round1_concepts, 1):\n",
    "    coef = round1_coefficients[concept]\n",
    "    print(f\"{i}. {concept}\")\n",
    "    print(f\"   Coefficient: {coef:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Round 1 Performance\n",
    "print(\"Round 1 Model Performance:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Training AUC:      {round1_performance['train_auc']:.3f}\")\n",
    "print(f\"Test AUC:          {round1_performance['test_auc']:.3f}\")\n",
    "print(f\"Training Accuracy: {round1_performance['train_accuracy']:.3f}\")\n",
    "print(f\"Test Accuracy:     {round1_performance['test_accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.3: Review Results\n",
    "\n",
    "> **Simulated Clinical Team Feedback**: \"A clinical team reviewing these results might notice that the concepts focus heavily on subjective temporal perception symptoms. They might suggest:\n",
    "> 1. Including more objective exam findings\n",
    "> 2. Considering risk factors like sleep schedule\n",
    "> 3. Being more specific about the types of temporal anomalies\"\n",
    "\n",
    "This feedback will guide our prompt modifications for Round 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Round 2: Incorporating Human Feedback\n",
    "\n",
    "Based on the clinical team's feedback, we modify our prompts to:\n",
    "1. Emphasize objective exam findings\n",
    "2. Include risk factor assessment\n",
    "3. Use more specific temporal anomaly descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 2: Modified prompt guidance (conceptual)\n",
    "round2_prompt_modifications = \"\"\"\n",
    "ROUND 2 PROMPT MODIFICATIONS:\n",
    "\n",
    "1. Added to baseline_init.txt:\n",
    "   \"Focus on objective findings from physical examination and standardized tests,\n",
    "    not just patient-reported symptoms.\"\n",
    "\n",
    "2. Added to bayesian_iter.txt:\n",
    "   \"Consider risk factors such as occupational exposure, sleep patterns,\n",
    "    and family history when generating new concept candidates.\"\n",
    "\n",
    "3. Added to concept_questions.txt:\n",
    "   \"Be specific about the type of temporal anomaly:\n",
    "    - Prospective (seeing future events)\n",
    "    - Retrospective (reliving past events)\n",
    "    - Cyclical (time loops)\"\n",
    "\"\"\"\n",
    "print(round2_prompt_modifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-computed results from Round 2 (with modified prompts)\n",
    "\n",
    "round2_concepts = [\n",
    "    \"Does the Temporal Orientation Test show abnormal results (predicting questions before asked)?\",\n",
    "    \"Does the patient have occupational exposure to quantum computing equipment?\",\n",
    "    \"Does the Clock Drawing Test show multiple overlapping clock faces?\",\n",
    "    \"Does the patient report prospective temporal anomalies (seeing events before they happen)?\",\n",
    "    \"Does the patient have irregular sleep-wake cycles?\",\n",
    "]\n",
    "\n",
    "round2_coefficients = {\n",
    "    \"Does the Temporal Orientation Test show abnormal results (predicting questions before asked)?\": 2.67,\n",
    "    \"Does the patient have occupational exposure to quantum computing equipment?\": 1.92,\n",
    "    \"Does the Clock Drawing Test show multiple overlapping clock faces?\": 1.78,\n",
    "    \"Does the patient report prospective temporal anomalies (seeing events before they happen)?\": 1.45,\n",
    "    \"Does the patient have irregular sleep-wake cycles?\": 0.89,\n",
    "}\n",
    "\n",
    "round2_performance = {\n",
    "    \"train_auc\": 0.93,\n",
    "    \"test_auc\": 0.88,\n",
    "    \"train_accuracy\": 0.87,\n",
    "    \"test_accuracy\": 0.82,\n",
    "}\n",
    "\n",
    "print(\"Round 2 Learned Concepts (After Human Feedback):\")\n",
    "print(\"=\" * 60)\n",
    "for i, concept in enumerate(round2_concepts, 1):\n",
    "    coef = round2_coefficients[concept]\n",
    "    print(f\"{i}. {concept}\")\n",
    "    print(f\"   Coefficient: {coef:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Round 1 vs Round 2 Performance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = ['Train AUC', 'Test AUC', 'Train Acc', 'Test Acc']\n",
    "r1_values = [round1_performance['train_auc'], round1_performance['test_auc'],\n",
    "             round1_performance['train_accuracy'], round1_performance['test_accuracy']]\n",
    "r2_values = [round2_performance['train_auc'], round2_performance['test_auc'],\n",
    "             round2_performance['train_accuracy'], round2_performance['test_accuracy']]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars1 = ax.bar(x - width/2, r1_values, width, label='Round 1', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, r2_values, width, label='Round 2', color='coral')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance: Round 1 vs Round 2')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0.7, 1.0)\n",
    "ax.axhline(y=0.85, color='gray', linestyle='--', alpha=0.5, label='Target')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nImprovement from Round 1 to Round 2:\")\n",
    "print(f\"  Test AUC:      +{round2_performance['test_auc'] - round1_performance['test_auc']:.3f}\")\n",
    "print(f\"  Test Accuracy: +{round2_performance['test_accuracy'] - round1_performance['test_accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Evolution Analysis\n",
    "\n",
    "Let's compare how the concepts evolved between rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONCEPT EVOLUTION: Round 1 -> Round 2\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"RETAINED (with refinement):\")\n",
    "print(\"  - 'Temporal Orientation Test' -> Now includes specific finding detail\")\n",
    "print()\n",
    "print(\"NEW CONCEPTS (from feedback):\")\n",
    "print(\"  + Occupational exposure to quantum equipment (risk factor)\")\n",
    "print(\"  + Clock Drawing Test findings (objective exam)\")\n",
    "print(\"  + Prospective temporal anomalies (specific type)\")\n",
    "print(\"  + Irregular sleep-wake cycles (risk factor)\")\n",
    "print()\n",
    "print(\"DROPPED CONCEPTS:\")\n",
    "print(\"  - Generic 'time moving at different speeds' (too vague)\")\n",
    "print(\"  - Generic 'feeling unstuck in time' (subjective, non-specific)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Interpreting the Final Model\n",
    "\n",
    "The final model from Round 2 is an interpretable linear combination of yes/no concept features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the final model coefficients\n",
    "concepts_short = [\n",
    "    \"Temporal Orientation Test\\nabnormal\",\n",
    "    \"Quantum equipment\\nexposure\",\n",
    "    \"Clock Drawing Test\\noverlapping\",\n",
    "    \"Prospective\\nanomalies\",\n",
    "    \"Irregular\\nsleep-wake\",\n",
    "]\n",
    "coefs = list(round2_coefficients.values())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(coefs)))\n",
    "bars = ax.barh(concepts_short, coefs, color=colors[::-1])\n",
    "ax.set_xlabel('Coefficient (Log-Odds)')\n",
    "ax.set_title('Final Model: Concept Coefficients')\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar, coef in zip(bars, coefs):\n",
    "    ax.text(coef + 0.05, bar.get_y() + bar.get_height()/2, f'{coef:.2f}',\n",
    "            va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction explanation\n",
    "print(\"EXAMPLE PREDICTION EXPLANATION\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Patient: QTDS-015\")\n",
    "print()\n",
    "print(\"Concept Extraction Results:\")\n",
    "example_features = {\n",
    "    \"Temporal Orientation Test abnormal\": 1,  # Yes\n",
    "    \"Quantum equipment exposure\": 1,           # Yes\n",
    "    \"Clock Drawing Test overlapping\": 0,       # No\n",
    "    \"Prospective anomalies\": 1,                # Yes\n",
    "    \"Irregular sleep-wake\": 0,                 # No\n",
    "}\n",
    "\n",
    "for concept, value in example_features.items():\n",
    "    print(f\"  {concept}: {'Yes' if value else 'No'}\")\n",
    "\n",
    "# Calculate log-odds\n",
    "log_odds = sum(coef * feat for coef, feat in zip(coefs, example_features.values()))\n",
    "probability = 1 / (1 + np.exp(-log_odds))\n",
    "\n",
    "print()\n",
    "print(f\"Model Calculation:\")\n",
    "print(f\"  Log-odds = {log_odds:.2f}\")\n",
    "print(f\"  P(QTDS)  = {probability:.2%}\")\n",
    "print()\n",
    "print(f\"Prediction: {'POSITIVE (QTDS likely)' if probability > 0.5 else 'NEGATIVE'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "This demo showed how HACHI enables iterative human-AI co-design:\n",
    "\n",
    "1. **Round 1**: AI agent generated initial concepts based on clinical notes\n",
    "   - Concepts were predictive but focused on subjective symptoms\n",
    "\n",
    "2. **Human Feedback**: Clinical team identified areas for improvement\n",
    "   - Need for objective exam findings\n",
    "   - Importance of risk factors\n",
    "   - Value of specific symptom characterization\n",
    "\n",
    "3. **Round 2**: Modified prompts incorporated feedback\n",
    "   - New concepts included objective tests and risk factors\n",
    "   - Performance improved (Test AUC: 0.84 -> 0.88)\n",
    "   - Model became more clinically interpretable\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To run HACHI on your own data:\n",
    "\n",
    "1. Prepare a CSV with clinical notes and outcomes\n",
    "2. Configure the `EnsembleConfig` with your parameters\n",
    "3. Run the training loop with `trainer.fit()`\n",
    "4. Review results and gather expert feedback\n",
    "5. Modify prompts based on feedback\n",
    "6. Iterate until satisfied with the model\n",
    "\n",
    "See the [README](../README.md) for detailed usage instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
